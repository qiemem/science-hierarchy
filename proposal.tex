% THIS IS SIGPROC-SP.TEX - VERSION 3.1
% WORKS WITH V3.2SP OF ACM_PROC_ARTICLE-SP.CLS
% APRIL 2009
%
% It is an example file showing how to use the 'acm_proc_article-sp.cls' V3.2SP
% LaTeX2e document class file for Conference Proceedings submissions.
% ----------------------------------------------------------------------------------------------------------------
% This .tex file (and associated .cls V3.2SP) *DOES NOT* produce:
%       1) The Permission Statement
%       2) The Conference (location) Info information
%       3) The Copyright Line with ACM data
%       4) Page numbering
% ---------------------------------------------------------------------------------------------------------------
% It is an example which *does* use the .bib file (from which the .bbl file
% is produced).
% REMEMBER HOWEVER: After having produced the .bbl file,
% and prior to final submission,
% you need to 'insert'  your .bbl file into your source .tex file so as to provide
% ONE 'self-contained' source file.
%
% Questions regarding SIGS should be sent to
% Adrienne Griscti ---> griscti@acm.org
%
% Questions/suggestions regarding the guidelines, .tex and .cls files, etc. to
% Gerald Murray ---> murray@hq.acm.org
%
% For tracking purposes - this is V3.1SP - APRIL 2009

\documentclass{acm_proc_article-sp}

\begin{document}

\title{Topic Analysis and Hierarchical Clustering on Scientific Papers}
%
% You need the command \numberofauthors to handle the 'placement
% and alignment' of the authors beneath the title.
%
% For aesthetic reasons, we recommend 'three authors at a time'
% i.e. three 'name/affiliation blocks' be placed beneath the title.
%
% NOTE: You are NOT restricted in how many 'rows' of
% "name/affiliations" may appear. We just ask that you restrict
% the number of 'columns' to three.
%
% Because of the available 'opening page real-estate'
% we ask you to refrain from putting more than six authors
% (two rows with three columns) beneath the article title.
% More than six makes the first-page appear very cluttered indeed.
%
% Use the \alignauthor commands to handle the names
% and affiliations for an 'aesthetic maximum' of six authors.
% Add names, affiliations, addresses for
% the seventh etc. author(s) as the argument for the
% \additionalauthors command.
% These 'additional authors' will be output/set for you
% without further effort on your part as the last section in
% the body of your article BEFORE References or any Appendices.

\numberofauthors{3} %  in this sample file, there are a *total*
% of EIGHT authors. SIX appear on the 'first-page' (for formatting
% reasons) and the remaining two appear in the \additionalauthors section.
%
\author{
% You can go ahead and credit any number of authors here,
% e.g. one 'row of three' or two rows (consisting of one row of three
% and a second row of one, two or three).
%
% The command \alignauthor (no curly braces needed) should
% precede each author name, affiliation/snail-mail address and
% e-mail address. Additionally, tag each line of
% affiliation/address with \affaddr, and tag the
% e-mail address with \email.
%
%
\alignauthor Raeed Chowdury\\
	\affaddr{Department of Biomedical Engineering}\\
	\affaddr{Northwestern University}\\
	\affaddr{633 Clark Street}\\
	\affaddr{Evanston, IL}\\
	\email{raeed@u.northwestern.edu}
\alignauthor Jeremy Needle\\
	\affaddr{Department of Linguistics}\\
	\affaddr{Northwestern University}\\
	\affaddr{633 Clark Street}\\
	\affaddr{Evanston, IL}\\
	\email{jneedle@ u.northwestern.edu}
\alignauthor Bryan Head\\
	\affaddr{Department of Electrical Engineering and Computer Science}\\
	\affaddr{Northwestern University}\\
	\affaddr{633 Clark Street}\\
	\affaddr{Evanston, IL}\\
	\email{bryan.head@ u.northwestern.edu}
}

\date{16 November 2012}

\maketitle
\begin{abstract}
	We will automatically find relationships between academic papers by determining keywords for each document, then clustering the documents into hierarchically-organized topic groups. We will verify the resulting topic groups with human judgments of relatedness.
\end{abstract}

\keywords{topic analysis, hierarchical clustering} % NOT required for Proceedings

\section{Intellectual Interest}
With the increase of  multidisciplinary scientific research, analyzing and clustering scientific papers by topic would allow researchers to be exposed to papers related to their work that they might not otherwise be aware of. Automatic analysis can avoid the preconceptions that would keep a researcher from recognizing related research outside of his immediate category. Additionally, it would allow researchers to more easily find other researchers to collaborate with.

\section{Dataset}
Our current top candidate is a dataset provided by Professor Konrad Kording (associated with Physiology and Applied Math). The dataset contains document titles, abstract, year of publication, journal, authors, and citations. The dataset is in MySQL, and it contains 48,222 documents. However, because judging the relatedness of abstracts in this dataset requires some expertise, this dataset is not ideal for our group, of which only one person has knowledge of neuroscience.

We are also using the arXiv database as another dataset.

\section{Task}
We will compare performance of multiple unsupervised learning algorithms in clustering documents hierarchically by topic using the words in the abstract as features.

We will restrict our analysis to the abstracts of the documents as the abstracts contain the words that best represent the content of the documents. To construct our feature space, we will first identify a corpus-wide list of significant words. These words will be identified by calculating each word's corpus-wide total TF-IDF score and then either thresholding or picking the $k$-best. Next, we will represent each document as a vector of its TF-IDF scores for each of the corpus-wide significant words. We will cluster on these vectors.

We are using vectors of TF-IDF scores as our feature space because they (ideally) identify which words are most significant to each document and the degree of that significance. We are limiting these vectors to a corpus-wide list of significant words to reduce dimensionality.

The dendrograms resulting from this process will be labeled with the core terms that distinguish each cluster. Hence, our results should be quite human readable, despite the high dimensionality of our feature space.

\section{Aspect of Task to Optimize}
Documents will be clustered by two techniques of bisecting k-means to produce a dendrogram of clustering levels to be evaluated later. First, we will use a traditional bisecting k-means method; second, we will use a method in which the feature set is recalculated by TF-IDF at each iteration \cite{robertson2004} \cite{aizawa2003}.

Note that relatively recent results have shown that bisecting k-means in general outperforms agglomerative methods for hierarchical clustering of documents.\cite{steinbach2000}\cite{zhao2005}

\section{Performance Evaluation}
We will evaluate the performance of this algorithm manually. We designed a forced-choice, XAB-format experiment to verify both our distance measure and our hypothesis that clustering adds value beyond that distance measure. In this experiment N subjects (N >= 3) will be shown a series (n = ~100) of random abstracts ('X'), then 2 more abstracts ('A', 'B'), with the task of simply choosing if A or B is more similar to the target X. For some stimuli, A and B are documents chosen at random with different distances from X; if subjects choose the closer document more than the farther one, this supports our distance measure as a measure of document similarity. For the other stimuli, A and B are equidistant from X, but X and A share a cluster, and B is not in that cluster. If subjects choose A as more similar more often, it supports the hypothesis that the clustering is adding something to the idea of similarity beyond the simple keyword distance.

Because of the size of the datasets and the feasible number of experimental subjects, we are constructing an experiment 'script' that can be presented in random order to get multiple subjects' ratings on the same XAB comparisons. This will sacrifice some breadth of the evaluation, but gives us greater support for each comparison.

\section{Software to be Developed}
\begin{itemize}
	\item Adapt/Implement k-means clustering (Python)
	\item Adapt/Implement iterative rebasing k-means clustering (Python)
	\item Adapt/Implement TF-IDF for keyword identification (Python)
	\item Keyword testing algorithm for thresholding
	\item Basic plumbing between the database and the learning algorithms (Python/SQL)
\end{itemize}

\section{Possible Software Packages to be Used}
\begin{itemize}
	\item MySQL (or some other SQL based database)
	\item tfidf (Python library)
	\item numpy (Python library)
	\item matplotlib (Python library)
\end{itemize}

\section{Job of Each Team Member}
\begin{tabular}{|l|l|}
	\hline
	Raeed Chowdhury & content specialist (neuro), stats\\
	\hline
	Bryan Head & primary coder, database person\\
	\hline
	Jeremy Needle & stats, TF-IDF, writeups\\
	\hline
\end{tabular}

\section{Milestones}

\begin{tabular}{|l|l|l|}
	\hline
	\multicolumn{1}{|c}{Milestone} & \multicolumn{1}{|c}{Member} & \multicolumn{1}{|c|}{Date}\\
	\hline \hline
	Data collected: Kording & Raeed & 11/9/2012 \\
	\hline
	Data collection: arXiv & Bryan & 11/16/2012 \\
	\hline
	Revised Proposal & -- & 11/16/2012 \\
	\hline
	Database hooks & Bryan & 11/18/2012\\
	\hline
	TF-IDF Verification & Jeremy & 11/19/2012\\
	\hline
	k-mean implementation & Bryan & 11/23/2012\\
	\hline
	Cluster Verification & Raeed & 11/26/2012\\
	\hline
	Cluster Performance Comparisons & Raeed, Jeremy & 12/3/2012\\
	\hline
	Initial Results & -- & 12/7/2012\\
	\hline
	Poster Session & -- & 12/13/2012\\
	\hline
\end{tabular}
%
% The following two commands are all you need in the
% initial runs of your .tex file to
% produce the bibliography for the citations in your paper.
\bibliographystyle{abbrv}
\nocite{*}
\bibliography{proposal}  % sigproc.bib is the name of the Bibliography in this case
% You must have a proper ".bib" file
%  and remember to run:
% latex bibtex latex latex
% to resolve all references
\end{document}
